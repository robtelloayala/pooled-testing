{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq \n",
    "from math import log, exp\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "def approx_model(q, u, n, T=1, G=5, K=17):\n",
    "    \"\"\"\n",
    "    Build cluster-based MILP model for Gurobi to solve. Finds an approximately\n",
    "    optimal testing allocation.\n",
    "    Inputs are three vectors indexed by cluster, as well as number of tests T\n",
    "    and pool size bound G, and accuracy parameter K.\n",
    "\n",
    "    q::Vector - avg. probability of being healthy for each cluster\n",
    "    u::Vector - utility for each cluster\n",
    "    n::Vector - size of each cluster\n",
    "    T::Int \t  - number of tests\n",
    "    G::Int    - pooled test size\n",
    "    K::Int \t  - number of segments of piecewise-linear fn approximating exp constraint\n",
    "    \"\"\"\n",
    "    # Verify that input is consistent\n",
    "    assert len(u) == len(q) == len(n), \"Input vectors have different lengths.\"\n",
    "    assert K >= 1, \"Number of segments for approximating exp must be at least 1.\"\n",
    "    assert T <= sum(n), \"Number of tests cannot exceed number of people in population.\"\n",
    "    assert all(isinstance(x, int) and x > 0 for x in u), \"Utilities must be strictly positive integers.\"\n",
    "    assert all(0 <= x <= 1 for x in q), \"Probabilities must (strictly) lie between 0 and 1.\"\n",
    "\n",
    "    # Compute some constants\n",
    "    C = len(n)  # number of clusters C\n",
    "    # Lower and upper bounds for z[t] = x[t]⋅u\n",
    "    L, U = min(u), G*max(u)\n",
    "    print(f\"L: {L}, U: {U}\")\n",
    "    # Lower and upper bounds for l[t] = log(x[t]⋅u) + sum(x[t,i]*log(q[i])\n",
    "    A = min(log(x) for x in u) + G*min(log(x) for x in q)\n",
    "    B = log(G*max(u)) + max(log(x) for x in q)\n",
    "    print(f\"A: {A}, B: {B}\")\n",
    "    tests = range(0, T)\n",
    "    clusters = range(0, C)\n",
    "    segments = range(0,K)\n",
    "\n",
    "    # Create model and set parameters\n",
    "    m = gp.Model('Test Allocation')\n",
    "    # m.setParam(\"TimeLimit\", 600)\n",
    "    # m.setParam(\"Presolve\", -1)\n",
    "    m.setParam('MIPGap', 0.01)\n",
    "\n",
    "    # Define variables\n",
    "    x = m.addVars(tests, clusters, lb = 0, vtype = GRB.INTEGER, name='x')\n",
    "    w = m.addVars(tests, lb=0, name='w')\n",
    "    l = m.addVars(tests, lb=-GRB.INFINITY, name='l')\n",
    "    y = m.addVars(tests, lb=-GRB.INFINITY, name='y')\n",
    "    z = m.addVars(tests, lb=-GRB.INFINITY, name='z')\n",
    "    # variables for log constraint\n",
    "    zind = m.addVars(tests, range(L,U+1), vtype=GRB.BINARY, name='zind')\n",
    "    # variables for approximating exp constraint\n",
    "    lind = m.addVars(tests, segments, vtype=GRB.BINARY, name='lind')\n",
    "    v = m.addVars(tests, segments, lb=-GRB.INFINITY, name='v')\n",
    "\n",
    "    # Set objective\n",
    "    m.setObjective(sum(w[t] for t in tests), GRB.MAXIMIZE)\n",
    "\n",
    "    # Add constraints\n",
    "    m.addConstrs(sum(x[t,i] for t in tests) <= n[i] for i in clusters)  # tests must be disjoint\n",
    "    m.addConstrs(1 <= sum(x[t,i] for i in clusters) for t in tests)  # pool size >= 1\n",
    "    m.addConstrs(sum(x[t,i] for i in clusters) <= G for t in tests)  # pool size <= G\n",
    "\n",
    "    # Log welfare constraints: l[t] == log(u ̇x[t]) + x[t] ̇log.(q)\n",
    "    m.addConstrs(l[t] == y[t] + sum(x[t,i] * log(q[i]) for i in clusters) for t in tests)\n",
    "\n",
    "    # Constraints to ensure y[t] <= log(z[t])\n",
    "    m.addConstrs(z[t] == sum(x[t,i] * u[i] for i in clusters) for t in tests)  # utility sums\n",
    "    # Use indictator variables t capture value of z[t]:\n",
    "    # z[t] is an integer in [L, U], so let zind[t,k] = 1 if z[t] = k and 0 otherwise.\n",
    "    m.addConstrs(1==sum(zind[t,k] for k in range(L,U+1)) for t in tests)  # exactly one zind entry is 1\n",
    "    m.addConstrs(z[t] == sum(k*zind[t,k] for k in range(L,U+1)) for t in tests)\n",
    "    m.addConstrs(y[t] <= sum(log(k)*zind[t,k] for k in range(L,U+1)) for t in tests)\n",
    "\n",
    "    # Deal with w[t] = exp(l[t])\n",
    "    if abs(B-A) < 1e-10:\n",
    "        m.addConstrs(l[t] == A for t in tests)\n",
    "        m.addConstrs(w[t] == exp(A) for t in tests)\n",
    "    else:\n",
    "        # Approximate w[t] <= exp(l[t]) using piecewise-linear function f with K segments on domain [A,B]\n",
    "        c = optimal_partition(A, B, K)  # compute optimal segmentation of interval [A, B]\n",
    "        a, b, c = linearise(exp, c)  # compute piecewise-linear function f on domain [A, B] with segmentation c\n",
    "        print(a, b, c)\n",
    "        # Use indicator variables `lind[t,k]` to capture in which segment the value of l[t] lies\n",
    "        # and let v[t,k] = l[t] if l[t] lies in (c[k], c[k+1]) and v[t,k] = 0 otherwise.\n",
    "        m.addConstrs(1 == sum(lind[t,k] for k in segments) for t in tests)\n",
    "        m.addConstrs(c[k]*lind[t,k] <= v[t,k] for t in tests for k in segments)\n",
    "        m.addConstrs(v[t,k] <= c[k+1]*lind[t,k] for t in tests for k in segments)\n",
    "        m.addConstrs(l[t] == sum(v[t,k] for k in segments) for t in tests)\n",
    "        # Ensure that w[t] <= f(l[t])\n",
    "        m.addConstrs(w[t] <= sum(a[k]*v[t,k] + b[k]*lind[t,k] for k in segments) for t in tests)\n",
    "\n",
    "    # Return model\n",
    "    return m, x\n",
    "\n",
    "def linearise(f, c):\n",
    "    \"\"\"\n",
    "    Compute the piecewise-linear representation of `f` with segments specified\n",
    "    in vector `c`.\n",
    "    \"\"\"\n",
    "    K = len(c)-1  # number of segments\n",
    "    a, b = np.zeros(K), np.zeros(K)\n",
    "    for k in range(0,K):\n",
    "        a[k] = (f(c[k+1]) - f(c[k])) / (c[k+1] - c[k])  # determine slope\n",
    "        b[k] = f(c[k+1]) - a[k]*c[k+1]  # determine residual\n",
    "    return a, b, c\n",
    "\n",
    "def delta(l, r):\n",
    "    \"\"\"\n",
    "    Compute maximum difference between segment (l, exp(l)) to (r, exp(r))\n",
    "    and exp(x) on the interval [l,r].\n",
    "    \"\"\"\n",
    "    if r <= l: return 0.0\n",
    "    a = (exp(l) - exp(r)) / (l - r)\n",
    "    if a == 0: return 0.0  # happens if l and r are sufficiently similar\n",
    "    b = exp(r) - a*r\n",
    "    result = a * log(a) + b - a  # maximum difference, derived from first order conditions\n",
    "    return max(0, result)  # slight hack to avoid numerical inaccuracies\n",
    "\n",
    "def partition(A, K, r1):\n",
    "    \"\"\"\n",
    "    Build a partition of K segments starting from A such that the\n",
    "    first segment is [A, A+r1] and all segments have the same error\n",
    "    ε identical to the error of the first segment.\n",
    "    \"\"\"\n",
    "    assert r1 >= 0\n",
    "    assert K > 0\n",
    "    c = [A]*(K+1)\n",
    "    if r1 == 0: return c\n",
    "    eps = delta(A, A + r1)  # error of the first segment [Lo, r1]\n",
    "    for k in range(0,K):\n",
    "        l = c[k]\n",
    "        # To define the bracket for the root finder, we make the reasonable\n",
    "        # assumption that the interval will be no larger than r1. (This can\n",
    "        # be proved easily, I believe).\n",
    "        r = brentq(lambda x : delta(l,x)-eps, l, l+r1+1)  # Finds r such that Δ(l,r) = ε.\n",
    "        c[k+1] = r\n",
    "    return c\n",
    "\n",
    "def optimal_partition(A, B, K):\n",
    "    \"\"\"\n",
    "    Find the optimal partition of [A, B] into K segments. Proceeds by searching\n",
    "    for the right size for the first segment: the size `r1` is right when\n",
    "    `partition(A, K, r1)` ends (approximately) at `B`.\n",
    "    \"\"\"\n",
    "    assert A < B\n",
    "    first = brentq(lambda x : partition(A, K, x)[-1]-B, 0, B-A+1)\n",
    "    c = partition(A, K, first)\n",
    "    c[K] = B  # to clean things up a bit\n",
    "    return c\n",
    "\n",
    "def compute_error(a,b,c):\n",
    "    \"\"\" Compute the maximum difference between the segments of the piecewise-linear function f(x) specified by a, b,\n",
    "    c and exp(x).\n",
    "\n",
    "    NB: For segment k, the difference is maximised at x = log(a[k]).\n",
    "    \"\"\"\n",
    "    ε = np.zeros(len(a))\n",
    "    for k in range(2,len(a)):\n",
    "        ε[k] = a[k]*np.log(a[k]) + b[k] - a[k]\n",
    "    return max(ε)\n",
    "\n",
    "##################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # import pandas as pd\n",
    "\n",
    "    # data = pd.read_csv('sample files/data.csv')\n",
    "\n",
    "    # date = '1970-01-01'\n",
    "    # dt = data.loc[data['timestamp'] == date]\n",
    "\n",
    "    # u = dt['u_m'] + dt['u_r'] + dt['u_p']\n",
    "    # q = dt['q']\n",
    "    # n = np.ones(len(q))\n",
    "    # m, x, w, l = approx_model(q, u, n, T=20, G=5, K=15, A=1, B=15)\n",
    "    # m.optimize()\n",
    "    # print(sum(v.X for v in x.values()))\n",
    "    # print(x)\n",
    "\n",
    "    # u = [1, 2]\n",
    "    # q = [0.1, 0.2]\n",
    "    # n = [1, 1]\n",
    "    # m, x = approx_model(q, u, n, T=2, G=1, K=1)\n",
    "    # m.write('python.lp')\n",
    "\n",
    "    u = [1]\n",
    "    q = [0.5]\n",
    "    n = [1]\n",
    "    m, x = approx_model(q, u, n, T=1, G=1, K=1)\n",
    "    m.optimize()\n",
    "    m.write('python2.lp')\n",
    "\n",
    "###############\n",
    "# pop = {'a':(0.1,1), 'b':(0.2,2), 'c':(0.8,4), 'd':(0.8,4)}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
